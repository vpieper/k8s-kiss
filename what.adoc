Kubernetes promises to provide the following features:

* Service discovery and load balancing.
* Storage orchestration.
* Automated rollouts and rollbacks.
* Automatic bin packaging.
* Self-healing.
* Secret and configuration management.

So when we talk about these topics, we get a bit lost. I have an application, and I want it to run. Looking at these points, it promises to tackle a lot of the concerns encountered when implementing a microservices architecture, or scaling applications.

Let me give you a quick introduction to three main concepts of Kubernetes.

Kubernetes will take our application, and deploy it in a pod. A pod is a small abstraction which contains one or more containers, grouped together. These are run on the Kubernetes nodes, which will be managed by the control plane. More on that later.

You can give Kubernetes a pod definition in yaml format, but you're better off taking the deployment route. A deployment is a wrapper around a replica sets. These are responsible for scaling pods up and down, depending on your configuration.

Finally, the last concept we use almost every time is a service. This is mainly a networking concept. A service is basically a definition of what traffic will be routed on which port, to which service. Given that we can label our pods, we can tell our services to scan for those labels and route accordingly, allowing a fairly straight forward service definition.

There are more indepth network tools available which allow to do a lot of things with the networking part of Kubernetes. If you're interested, take a look at ingress and egress controllers. I'll cover these at a later webinar.